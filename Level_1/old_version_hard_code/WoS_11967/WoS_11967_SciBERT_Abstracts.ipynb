{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRuetRKhDN59",
        "outputId": "8cffd255-f193-4e26-a2a1-24c913dd2a9e"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BMB0YxADN5-",
        "outputId": "376a9d42-308c-48e0-8bfb-1c9a84d9c2de"
      },
      "outputs": [],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2qEb3ivDN5-",
        "outputId": "5b09f1c2-4a37-4058-b87c-8e6f7094b228"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRaneJBnDN5_",
        "outputId": "cf79b160-48eb-41d5-944b-741c96fdf66a"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEVF9FbODN5_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "import torch.nn.functional as F\n",
        "from tqdm import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.utils\n",
        "import time\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d84lKOxcDN5_",
        "outputId": "cc59657c-b3bc-438e-ed4c-ff186ad0c671"
      },
      "outputs": [],
      "source": [
        "# Retrive the data from stored dataset\n",
        "dataDir = \"/content/drive/MyDrive/WoS/data/X11967\"\n",
        "tsvData = os.path.join(dataDir,\"WoSDataset_11967.tsv\")\n",
        "\n",
        "tsvData = np.loadtxt(tsvData, dtype=str, delimiter=\"\\t\")\n",
        "print(np.shape(tsvData))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIYp3nhcDN5_",
        "outputId": "854a1f0a-9078-43e7-af7f-610e1a4d7283"
      },
      "outputs": [],
      "source": [
        "print(tsvData[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUvZlOibDN5_"
      },
      "outputs": [],
      "source": [
        "allLabels = tsvData[:,0]\n",
        "domains = tsvData[:,1]\n",
        "keywords = tsvData[:,2]\n",
        "abstracts = tsvData[:,3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SE5jkqySDN6A",
        "outputId": "14123d76-ca41-4394-8a80-386997de36a8"
      },
      "outputs": [],
      "source": [
        "labels = np.unique(domains, return_counts=True)[0]\n",
        "labelCounts=  np.unique(domains, return_counts=True)[1]\n",
        "\n",
        "print(\"Labels \", labels)\n",
        "print(\"Label counts \", labelCounts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "4wUHmcLtDN6A",
        "outputId": "8629c1ca-c3ae-4b11-d33f-b97a5acfabd9"
      },
      "outputs": [],
      "source": [
        "# Visualize domain counts in dataset\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Domain Counts (Dataset)\")\n",
        "plt.pie(labelCounts, labels=labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired(range(len(labels))))\n",
        "plt.axis('equal')\n",
        "plt.show()\n",
        "\n",
        "for i, domain in enumerate(labels):\n",
        "    print(\"The domain\", domain, \"has\", labelCounts[i], \"records in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy4b69DrDN6A",
        "outputId": "9974fe7e-a5ad-4385-8e87-332cb95c4f43"
      },
      "outputs": [],
      "source": [
        "# Shuffle data\n",
        "dataShuffled = sklearn.utils.shuffle(tsvData)\n",
        "\n",
        "abstractsShuffled = dataShuffled[:,3]\n",
        "keywordsShuffled = dataShuffled[:,2]\n",
        "domainsShuffled = dataShuffled[:,1]\n",
        "allLabelsShuffled = dataShuffled[:,0]\n",
        "\n",
        "print(\"Number of abstracts: \", len(abstractsShuffled))\n",
        "print(\"Shape of abstracts: \", np.shape(abstractsShuffled))\n",
        "print(abstractsShuffled[0:2])\n",
        "\n",
        "print(\"Number of keywords: \", len(keywordsShuffled))\n",
        "print(\"Shape of keywords: \", np.shape(keywordsShuffled))\n",
        "print(abstractsShuffled[0:2])\n",
        "\n",
        "print(\"Number of domains: \", len(domainsShuffled))\n",
        "print(\"Shape of domains: \", np.shape(domainsShuffled))\n",
        "print(domainsShuffled[0:2])\n",
        "\n",
        "print(\"Number of labels: \", len(allLabelsShuffled))\n",
        "print(\"Shape of labels: \", np.shape(allLabelsShuffled))\n",
        "print(allLabelsShuffled[0:2])\n",
        "\n",
        "\n",
        "# Convert labels to integer\n",
        "allLabelsDigitShuffled = allLabelsShuffled.astype(int)\n",
        "\n",
        "print(abstractsShuffled[0:10])\n",
        "print(keywordsShuffled[0:10])\n",
        "print(domainsShuffled[0:10])\n",
        "print(allLabelsShuffled[0:10])\n",
        "print(allLabelsDigitShuffled[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE8v68D2DN6A",
        "outputId": "70923055-dbb9-4e17-f42a-59ee95975297"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training and testing (80/20 split)\n",
        "train_data, test_data = train_test_split(dataShuffled, test_size=0.2, random_state=42)\n",
        "print(np.shape(train_data))\n",
        "print(np.shape(test_data))\n",
        "\n",
        "# Further split training data into training and validation (80/20 split of training set)\n",
        "_, val_data = train_test_split(test_data, test_size=0.2, random_state=42)\n",
        "print(np.shape(train_data))\n",
        "print(np.shape(test_data))\n",
        "print(np.shape(val_data))\n",
        "# Load SciBERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/scibert_scivocab_uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONFXZGUUDN6A",
        "outputId": "3a77f8ea-392f-4a2a-bb78-920341b05a95"
      },
      "outputs": [],
      "source": [
        "abstractsTrain = train_data[:,3]\n",
        "keywordsTrain = train_data[:,2]\n",
        "domainsTrain = train_data[:,1]\n",
        "allLabelsTrain = train_data[:,0]\n",
        "\n",
        "print(\"Number of abstracts: \",len(abstractsTrain))\n",
        "print(\"Shape of abstracts: \",np.shape(abstractsTrain))\n",
        "print(\"Number of keywords: \",len(keywordsTrain))\n",
        "print(\"Shape of keywords: \",np.shape(keywordsTrain))\n",
        "print(\"Number of domains: \",len(domainsTrain))\n",
        "print(\"Shape of domains: \",np.shape(domainsTrain))\n",
        "print(\"Number of labels: \",len(allLabelsTrain))\n",
        "print(\"Shape of labels: \",np.shape(allLabelsTrain))\n",
        "\n",
        "print(abstractsTrain[0:2])\n",
        "print(keywordsTrain[0:2])\n",
        "print(domainsTrain[0:2])\n",
        "print(allLabelsTrain[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "RBJjrIkeDN6A",
        "outputId": "5c37a5d2-7df9-4de7-848f-4d1479911f5f"
      },
      "outputs": [],
      "source": [
        "labels = np.unique(domainsTrain, return_counts=True)[0]\n",
        "labelCounts =  np.unique(domainsTrain, return_counts=True)[1]\n",
        "\n",
        "print(\"Labels \", labels)\n",
        "print(\"Label counts \", labelCounts)\n",
        "\n",
        "nAbstract = len(abstractsTrain)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Domain Counts (Training Set)\")\n",
        "plt.pie(labelCounts, labels=labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired(range(len(labels))))\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()\n",
        "\n",
        "for i, domain in enumerate(labels):\n",
        "    print(\"The domain\", domain, \"has\", labelCounts[i], \"records in the training set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4urSnRFDN6B",
        "outputId": "4d3fae4a-1dfc-4d43-87d5-4a9dc72576ea"
      },
      "outputs": [],
      "source": [
        "abstractsTest = test_data[:,3]\n",
        "keywordsTest = test_data[:,2]\n",
        "domainsTest = test_data[:,1]\n",
        "allLabelsTest = test_data[:,0]\n",
        "\n",
        "print(\"Number of abstracts: \",len(abstractsTest))\n",
        "print(\"Shape of abstracts: \",np.shape(abstractsTest))\n",
        "print(\"Number of keywords: \",len(keywordsTest))\n",
        "print(\"Shape of keywords: \",np.shape(keywordsTest))\n",
        "print(\"Number of domains: \",len(domainsTest))\n",
        "print(\"Shape of domains: \",np.shape(domainsTest))\n",
        "print(\"Number of labels: \",len(allLabelsTest))\n",
        "print(\"Shape of labels: \",np.shape(allLabelsTest))\n",
        "\n",
        "# arr = np.array(domainsTest)\n",
        "# cleaned_domains = np.char.strip(arr)\n",
        "# print(\"Cleaned arr \", cleaned_domains)\n",
        "# domainsLabelsTest = cleaned_domains\n",
        "# print(\"Labels domains \", domainsLabelsTest)\n",
        "\n",
        "print(abstractsTest[0:2])\n",
        "print(keywordsTest[0:2])\n",
        "print(domainsTest[0:2])\n",
        "print(allLabelsTest[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "wXDx7H28DN6B",
        "outputId": "cf0c6ebc-ef14-4158-e37c-485e6943e8c0"
      },
      "outputs": [],
      "source": [
        "labels = np.unique(domainsTest, return_counts=True)[0]\n",
        "labelCounts =  np.unique(domainsTest, return_counts=True)[1]\n",
        "\n",
        "print(\"Labels \", labels)\n",
        "print(\"Label counts \", labelCounts)\n",
        "\n",
        "nAbstract = len(abstractsTest)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Domain Counts (Test Set)\")\n",
        "plt.pie(labelCounts, labels=labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired(range(len(labels))))\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()\n",
        "\n",
        "for i, domain in enumerate(labels):\n",
        "    print(\"The domain\", domain, \"has\", labelCounts[i], \"records in the test set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkEyui06DN6B",
        "outputId": "db6a8474-b327-4b3e-f205-0ea081510dc0"
      },
      "outputs": [],
      "source": [
        "abstractsVal = val_data[:,3]\n",
        "keywordsVal = val_data[:,2]\n",
        "domainsVal = val_data[:,1]\n",
        "allLabelsVal = val_data[:,0]\n",
        "\n",
        "print(\"Number of abstracts: \",len(abstractsVal))\n",
        "print(\"Shape of abstracts: \",np.shape(abstractsVal))\n",
        "print(\"Number of keywords: \",len(keywordsVal))\n",
        "print(\"Shape of keywords: \",np.shape(keywordsVal))\n",
        "print(\"Number of domains: \",len(domainsVal))\n",
        "print(\"Shape of domains: \",np.shape(domainsVal))\n",
        "print(\"Number of labels: \",len(allLabelsVal))\n",
        "print(\"Shape of labels: \",np.shape(allLabelsVal))\n",
        "\n",
        "print(abstractsVal[0:2])\n",
        "print(keywordsVal[0:2])\n",
        "print(domainsVal[0:2])\n",
        "print(allLabelsVal[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "1ax8-nZaDN6B",
        "outputId": "028fe253-1a22-4df7-87ea-1d7fc3048c62"
      },
      "outputs": [],
      "source": [
        "labels = np.unique(domainsVal, return_counts=True)[0]\n",
        "labelCounts =  np.unique(domainsVal, return_counts=True)[1]\n",
        "\n",
        "print(\"Labels \", labels)\n",
        "print(\"Label counts \", labelCounts)\n",
        "\n",
        "nAbstract = len(abstractsVal)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Domain Counts (Validation Set)\")\n",
        "plt.pie(labelCounts, labels=labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired(range(len(labels))))\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()\n",
        "\n",
        "for i, domain in enumerate(labels):\n",
        "    print(\"The domain\", domain, \"has\", labelCounts[i], \"records in the vaidation set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxbOFbMrDN6C"
      },
      "outputs": [],
      "source": [
        "# Function to tokenize and encode the dataset\n",
        "def encode_data(data, tokenizer, max_length=128):\n",
        "    # print(len(data[:,2]))\n",
        "    inputs = tokenizer(\n",
        "        data[:,3].tolist(), # abstracts\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    # print(len(dataShuffled[:, 0]))\n",
        "    labels = torch.tensor(data[:, 0].astype(int))\n",
        "    print(\"Label length \", len(labels))\n",
        "    return TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8_HDuDUDN6C",
        "outputId": "9ab58d6a-df0e-489d-c734-174992ba6ce1"
      },
      "outputs": [],
      "source": [
        "print(np.shape(train_data))\n",
        "print(np.shape(test_data))\n",
        "print(np.shape(val_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6avATPgDN6C",
        "outputId": "37d028ab-e91f-4003-f034-947af41afc3e"
      },
      "outputs": [],
      "source": [
        "# Encode training, validation, and testing data\n",
        "train_dataset = encode_data(train_data, tokenizer)\n",
        "val_dataset = encode_data(val_data, tokenizer)\n",
        "test_dataset = encode_data(test_data, tokenizer)\n",
        "\n",
        "\n",
        "\n",
        "# Data loaders\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32)\n",
        "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=32)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybVLIN-JDN6C",
        "outputId": "3cc4db3c-d2ff-4c7e-cea3-46b958907d99"
      },
      "outputs": [],
      "source": [
        "# Load SciBERT model\n",
        "print(len(np.unique(train_data[:,0])))\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"allenai/scibert_scivocab_uncased\", num_labels=len(np.unique(train_data[:,0])))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps1DInjXDN6C",
        "outputId": "f816e336-1471-4912-efed-05432a1a4c7e"
      },
      "outputs": [],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmjlyLnkDN6C",
        "outputId": "20407602-f0ca-4749-c802-68bb3165567a"
      },
      "outputs": [],
      "source": [
        "# Optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "total_steps = len(train_dataloader) * 20\n",
        "num_warmup_steps = 1e-4\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj4AnpxJDN6C"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(valType, predictions, true_labels):\n",
        "    # Confusion matrix\n",
        "    if(valType == 'test'):\n",
        "        cm = confusion_matrix(true_labels, predictions)\n",
        "        print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "        # Classification report (includes precision, recall, F1 score)\n",
        "        report = classification_report(true_labels, predictions, target_names=[str(i) for i in range(len(np.unique(true_labels)))])\n",
        "        print(\"\\nClassification Report:\\n\", report)\n",
        "\n",
        "        # Calculate different types of F1 scores, precision, and recall\n",
        "        f1_macro = f1_score(true_labels, predictions, average='macro')\n",
        "        f1_micro = f1_score(true_labels, predictions, average='micro')\n",
        "        f1_weighted = f1_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        precision_macro = precision_score(true_labels, predictions, average='macro')\n",
        "        precision_micro = precision_score(true_labels, predictions, average='micro')\n",
        "        precision_weighted = precision_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        recall_macro = recall_score(true_labels, predictions, average='macro')\n",
        "        recall_micro = recall_score(true_labels, predictions, average='micro')\n",
        "        recall_weighted = recall_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        print(f\"Macro F1 Score: {f1_macro}\")\n",
        "        print(f\"Micro F1 Score: {f1_micro}\")\n",
        "        print(f\"Weighted F1 Score: {f1_weighted}\")\n",
        "\n",
        "        print(f\"Macro Precision: {precision_macro}\")\n",
        "        print(f\"Micro Precision: {precision_micro}\")\n",
        "        print(f\"Weighted Precision: {precision_weighted}\")\n",
        "\n",
        "        print(f\"Macro Recall: {recall_macro}\")\n",
        "        print(f\"Micro Recall: {recall_micro}\")\n",
        "        print(f\"Weighted Recall: {recall_weighted}\")\n",
        "\n",
        "    elif(valType == 'val'):\n",
        "        cm = confusion_matrix(true_labels, predictions)\n",
        "        f1_macro = f1_score(true_labels, predictions, average='macro')\n",
        "        f1_micro = f1_score(true_labels, predictions, average='micro')\n",
        "        f1_weighted = f1_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        precision_macro = precision_score(true_labels, predictions, average='macro')\n",
        "        precision_micro = precision_score(true_labels, predictions, average='micro')\n",
        "        precision_weighted = precision_score(true_labels, predictions, average='weighted')\n",
        "\n",
        "        recall_macro = recall_score(true_labels, predictions, average='macro')\n",
        "        recall_micro = recall_score(true_labels, predictions, average='micro')\n",
        "        recall_weighted = recall_score(true_labels, predictions, average='weighted')\n",
        "        # print('Val Micro F1:', f1_micro)\n",
        "        return f1_micro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05xzH0FEDN6C",
        "outputId": "4e9b636b-202f-4c68-c754-dc0053905050"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Training\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, labels = batch\n",
        "\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=input_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for batch in val_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids=input_ids, attention_mask=input_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "        batch_predictions = np.argmax(logits, axis=1)\n",
        "        predictions.extend(batch_predictions)\n",
        "        true_labels.extend(label_ids)\n",
        "\n",
        "    val_micro_f1 = calculate_metrics('val', predictions, true_labels)\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Print epoch summary\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    print(f\"  Train Loss: {avg_train_loss}\")\n",
        "    print(f\"  Val Micro F1: {val_micro_f1}\")\n",
        "    print(f\"  Time: {elapsed_time // 60:.0f}m {elapsed_time % 60:.0f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF1GCpcUDN6D",
        "outputId": "6a2bfbff-56bf-42a3-f74d-09757586129e"
      },
      "outputs": [],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, input_mask, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=input_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "    batch_predictions = np.argmax(logits, axis=1)\n",
        "    predictions.extend(batch_predictions)\n",
        "    true_labels.extend(label_ids)\n",
        "\n",
        "# Calculate and print metrics\n",
        "calculate_metrics('test', predictions, true_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBU4h6E7DN6D"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/WoS/SciBERT_WoS_Abstracts_11967')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
